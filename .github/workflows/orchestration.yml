name: Orchestrator

on:
  schedule:
    - cron: "*/5 * * * *"  # Runs every 5 minutes
  workflow_dispatch:  # Allows manual trigger

jobs:
  orchestrate-simulation:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.9"

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Make Dropbox Script Executable
        run: chmod +x src/download_from_dropbox.sh

      - name: Download, Inject Parameters, and Upload to Dropbox
        env:
          APP_KEY: ${{ secrets.APP_KEY }}
          APP_SECRET: ${{ secrets.APP_SECRET }}
          REFRESH_TOKEN: ${{ secrets.REFRESH_TOKEN }}
        run: |
          echo "üì• Starting Dropbox download and cleanup..."
          src/download_from_dropbox.sh

          echo "üîß Injecting randomized parameters into flow_data.json..."
          python3 - <<EOF
          import json, random, os

          path = "data/testing-input-output/flow_data.json"
          if not os.path.exists(path):
              print("‚ùå flow_data.json not found. Skipping injection.")
              exit(1)

          with open(path) as f:
              data = json.load(f)

          data["fluid_properties"]["density"] = round(random.uniform(0.8, 1.2), 3)
          data["fluid_properties"]["viscosity"] = round(random.uniform(0.05, 0.15), 3)
          data["initial_conditions"]["initial_velocity"] = [round(random.uniform(-1, 1), 6) for _ in range(3)]
          data["initial_conditions"]["initial_pressure"] = round(random.uniform(100, 200), 3)

          with open(path, "w") as f:
              json.dump(data, f, indent=2)

          print("‚úÖ Injection complete. New values:")
          print(json.dumps(data["fluid_properties"], indent=2))
          print(json.dumps(data["initial_conditions"], indent=2))
          EOF

          echo "üì§ Uploading updated files to Dropbox..."
          src/upload_to_dropbox.sh

      - name: Append Run Log to README
        env:
          GIT_USER_NAME: ${{ secrets.GIT_USER_NAME }}
          GIT_USER_EMAIL: ${{ secrets.GIT_USER_EMAIL }}
        run: |
          TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')
          FLOW_JSON="data/testing-input-output/flow_data.json"

          DENSITY=$(jq '.fluid_properties.density' $FLOW_JSON)
          VISCOSITY=$(jq '.fluid_properties.viscosity' $FLOW_JSON)
          PRESSURE=$(jq '.initial_conditions.initial_pressure' $FLOW_JSON)
          VELOCITY=$(jq -r '.initial_conditions.initial_velocity | @csv' $FLOW_JSON)

          # Ensure README starts with disable instructions (only once)
          if ! grep -q "üõë To temporarily disable the orchestrator workflow:" README.md; then
            {
              echo "# engineering_simulations_pipeline_auto_test"
              echo ""
              echo "üõë To temporarily disable the orchestrator workflow:"
              echo "1. Go to your GitHub repository."
              echo "2. Click the **Actions** tab."
              echo "3. Select the **Orchestrator** workflow from the left sidebar."
              echo "4. Click the **Disable workflow** button near the top-right."
              echo ""
              echo "üîÑ To start a new simulation run later:"
              echo "1. Re-enable the workflow from the same Actions tab."
              echo "2. Upload new input files to Dropbox."
              echo "3. Wait for the next scheduled run or trigger manually."
              echo ""
              echo "## Simulation Run History"
              echo "| Timestamp | Density | Viscosity | Initial Pressure | Initial Velocity |"
              echo "|-----------|---------|-----------|------------------|-------------------|"
            } > README.md
          fi

          echo "| $TIMESTAMP | $DENSITY | $VISCOSITY | $PRESSURE | [$VELOCITY] |" >> README.md

          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git add README.md
          git commit -m "Log run at $TIMESTAMP"
          git push origin main

      - name: Trigger Downstream Workflows via GitHub API
        env:
          GIT_PAT: ${{ secrets.GIT_PAT }}
        run: |
          INPUT_DIR="data/testing-input-output"
          TIMESTAMP=$(date "+%Y-%m-%d %H:%M:%S")

          trigger_workflow() {
            REPO="$1"
            WORKFLOW_FILE="$2"
            echo "üöÄ Dispatching $WORKFLOW_FILE in $REPO"

            curl -X POST \
              -H "Authorization: token $GIT_PAT" \
              -H "Accept: application/vnd.github.v3+json" \
              https://api.github.com/repos/$REPO/actions/workflows/$WORKFLOW_FILE/dispatches \
              -d '{"ref":"main"}'
          }

          # Domain Grid Trigger
          if ls "$INPUT_DIR"/*.step &>/dev/null && [ -f "$INPUT_DIR/flow_data.json" ] && [ ! -f "$INPUT_DIR/enriched_metadata.json" ]; then
            trigger_workflow "Dmitrii-Zavalin-Deployments/engineering_simulations_pipeline_domain_grid_sred" "fluid_simulation_pipeline.yml"
          else
            echo "‚ÑπÔ∏è Skipped Domain Grid Trigger: 'enriched_metadata.json' already exists."
            echo "üìù To regenerate it, delete in Dropbox 'engineering_simulations_pipeline/enriched_metadata.json' and rerun the orchestrator. See README.md in the domain grid repository for details."
          fi

          # Boundary Mapping Trigger
          if ls "$INPUT_DIR"/*.step &>/dev/null && [ -f "$INPUT_DIR/flow_data.json" ] && [ ! -f "$INPUT_DIR/boundary_conditions_gmsh.json" ]; then
            trigger_workflow "Dmitrii-Zavalin-Deployments/engineering_simulations_pipeline_boundary_mapping_sred" "boundary_conditions_workflow.yml"
          else
            echo "‚ÑπÔ∏è Skipped Boundary Mapping Trigger: 'boundary_conditions_gmsh.json' already exists."
            echo "üìù To regenerate it, delete in Dropbox 'engineering_simulations_pipeline/boundary_conditions_gmsh.json' and rerun the orchestrator. See README.md in the boundary mapping repository for details."
          fi

          # Geometry Masking Trigger
          if ls "$INPUT_DIR"/*.step &>/dev/null && [ -f "$INPUT_DIR/flow_data.json" ] && [ ! -f "$INPUT_DIR/geometry_masking_gmsh.json" ]; then
            trigger_workflow "Dmitrii-Zavalin-Deployments/engineering_simulations_pipeline_geometry_masking_sred" "geometry_masking_workflow.yml"
          else
            echo "‚ÑπÔ∏è Skipped Geometry Masking Trigger: 'geometry_masking_gmsh.json' already exists."
            echo "üìù To regenerate it, delete in Dropbox 'engineering_simulations_pipeline/geometry_masking_gmsh.json' and rerun the orchestrator. See README.md in the geometry masking repository for details."
          fi

          # Input Builder Trigger
          if [ -f "$INPUT_DIR/enriched_metadata.json" ] && \
             [ -f "$INPUT_DIR/boundary_conditions_gmsh.json" ] && \
             [ -f "$INPUT_DIR/geometry_masking_gmsh.json" ] && \
             [ ! -f "$INPUT_DIR/fluid_simulation_input.json" ]; then
            trigger_workflow "Dmitrii-Zavalin-Deployments/engineering_simulations_pipeline_input_builder_sred" "fluid_simulation_pipeline.yml"
          else
            echo "‚ÑπÔ∏è Skipped Input Builder Trigger: 'fluid_simulation_input.json' already exists."
            echo "üìù To regenerate it, delete in Dropbox 'engineering_simulations_pipeline/fluid_simulation_input.json' and rerun the orchestrator. See README.md in the input builder repository for details."
          fi

          # Fluid Dynamics Solver Trigger
          if [ -f "$INPUT_DIR/fluid_simulation_input.json" ] && \
             [ ! -f "$INPUT_DIR/navier_stokes_output.zip" ]; then
            trigger_workflow "Dmitrii-Zavalin-Deployments/engineering_simulations_pipeline_fluid_dynamics_solver_sred" "fluid_dynamics_calculations.yml"
          else
            echo "‚ÑπÔ∏è Skipped Fluid Dynamics Solver Trigger: 'navier_stokes_output.zip' already exists."
            echo "üìù To regenerate it, delete in Dropbox 'engineering_simulations_pipeline/navier_stokes_output.zip' and rerun the orchestrator. See README.md in the fluid solver repository for details."
          fi



